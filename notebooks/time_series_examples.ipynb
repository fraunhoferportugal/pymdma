{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"pymdma[time_series]\" --find-links \"https://download.pytorch.org/whl/cpu/torch_stable.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data that simulates both real and synthetic samples for metric computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sig_file(file_path: Path):\n",
    "    \"\"\"Read a signal file from the supported file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path: Union[str, Path])\n",
    "        Path to the file.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing the data from the .mat file.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If a file extension different from .mat is found.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    # Check if the file has a .mat extension\n",
    "    if file_path.suffix in [\".mat\", \".dat\"]:\n",
    "        directory_path = file_path.parent\n",
    "        return wfdb.rdsamp(directory_path / file_path.stem)[0]\n",
    "    else:\n",
    "        # Raise a ValueError for files with unsupported extensions\n",
    "        raise AssertionError(f\"Unsupported file extension: {Path(file_path).suffix} (file: {file_path})\")\n",
    "\n",
    "\n",
    "def extract_fs_dims(file_path):\n",
    "    \"\"\"Extracts the sampling frequency and the dimension names of the signal\n",
    "    from a header file. Only works for this specific .hea file structure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: str\n",
    "        The path to the header file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fs : int\n",
    "        Sampling frequency.\n",
    "    dims: List(str)\n",
    "        Names of the signal dimensions.\n",
    "    \"\"\"\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "    dims = [lines[i].strip().split(\" \")[-1] for i in range(1, 13)]\n",
    "    fs = lines[0].strip().split(\" \")[2]\n",
    "    return int(fs), dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# List signal files from source dirs\n",
    "target_data_path = Path(parent_dir + \"/data/test/time_series/synthesis_val/dataset/\")\n",
    "reference_data_path = Path(parent_dir + \"/data/test/time_series/synthesis_val/reference/\")\n",
    "ref_sig_files = [sig for sig in reference_data_path.glob(\"**/*\") if sig.suffix in {\".mat\", \".dat\", \".csv\"}]\n",
    "target_sig_files = [sig for sig in target_data_path.glob(\"**/*\") if sig.suffix in {\".mat\", \".dat\", \".csv\"}]\n",
    "\n",
    "# Read signal files\n",
    "ref_data = np.array([read_sig_file(sig_file) for sig_file in ref_sig_files])\n",
    "target_data = np.array([read_sig_file(sig_file) for sig_file in target_sig_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Explore data shapes and plot Lead I of a real ECG tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acess shape\n",
    "shape_ref = ref_data.shape\n",
    "shape_target = target_data.shape\n",
    "\n",
    "print(\n",
    "    f\"Reference/Real data Shape: {shape_ref} | {shape_ref[0]} ECG tracings, each {shape_ref[1]} samples long with {shape_ref[2]} channels\"\n",
    ")\n",
    "print(\n",
    "    f\"Target/Synthetic data Shape: {shape_target} | {shape_target[0]} tracings, each {shape_target[1]} samples long with {shape_target[2]} channels\"\n",
    ")\n",
    "\n",
    "# Plot Lead I of a Real ECG Signal\n",
    "plt.plot(ref_data[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_instances_score(signals: list[np.ndarray], metric: str, scores: list[float], n_cols: int = 5):\n",
    "    n_rows = len(signals) // n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "    for ax, signal, score in zip(axs.flat, signals, scores):\n",
    "        ax.plot(signal[:, 0])  # ploting only Lead I of the ECG signal\n",
    "        ax.set_title(f\"{metric}: {score:.3f}\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    # Add a title to the entire figure\n",
    "    fig.suptitle(\"ECG Signals with SNR Annotation (All Leads Considered, Lead I Shown)\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Validation\n",
    "\n",
    "\n",
    "In the time series modality, the `pymdma` package offers one type of input validation, **no-reference**, where the signal is validated independently, without requiring a reference signal.\n",
    "\n",
    "This section demonstrates how to use the input validation functions with the signal-to-noise ratio (`SNR`) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.time_series.measures.input_val import Uniqueness\n",
    "\n",
    "uniqueness = Uniqueness()\n",
    "uniqueness_result = uniqueness.compute(ref_data)  # compute the metric\n",
    "_dataset_level, instance_level = uniqueness_result.value  # fetch the instance level results\n",
    "\n",
    "plot_instances_score(ref_data, \"Uniqueness\", instance_level, n_cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.time_series.measures.input_val.data.quality import SNR\n",
    "\n",
    "snr = SNR()\n",
    "snr_result = snr.compute(ref_data)  # compute the metric\n",
    "_dataset_level, instance_level = snr_result.value  # fetch the instance level results\n",
    "\n",
    "\n",
    "plot_instances_score(ref_data, \"SNR\", instance_level, n_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the metric results\n",
    "\n",
    "We provide a simple method in the `MetricResult` class to easily plot the results of the metrics. The method `plot()` will plot the results of the metrics in the format specified by the `plot_params` attribute in the `MetricResult` class. The `plot_params` attribute is a dictionary that contains the parameters to be used in the plot. If this attribute is not set, the method will default to a bar plot.\n",
    "\n",
    "You can provide a title for the plot when calling this method, as well as an axis is which you wish to plot the results (helpfull when plotting multiple metrics in the same plot). In addition, you can provide a set of `plot_params` to be used directly by matplotlib's plotting functions.\n",
    "\n",
    "> **Note**: You also have access to the values of the metrics via the `values` attribute in the `MetricResult` class. You can use these values to plot the results using your own plotting functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_result.plot(\"Signal to Noise Ratio\")  # plot the results from the result object\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Validation\n",
    "\n",
    "The automatic evaluation of synthetically generated signals is a common practice in the field of generative AI, and is crucial for the assessment of the quality of large synthetic datasets. This is usually done by comparing the synthetic signals to a set of reference signals by considering the similarity between the distributions of the two sets. In this section, we will demonstrate how to use the `pymdma` package to evaluate the quality of synthetic signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.time_series.models.features import ExtractorFactory\n",
    "\n",
    "# Extract the sampling frequency and the dimension names of the signal from a header file\n",
    "hea_ref = ref_sig_files[0].parent / f\"{ref_sig_files[0].stem}.hea\"\n",
    "hea_target = target_sig_files[0].parent / f\"{target_sig_files[0].stem}.hea\"\n",
    "ref_fs, ref_dim = extract_fs_dims(hea_ref)\n",
    "target_fs, target_dim = extract_fs_dims(hea_target)\n",
    "\n",
    "\n",
    "# Get features for synthetic data quality metrics computation\n",
    "tsfel = ExtractorFactory.model_from_name(\"tsfel\", verbose=False)\n",
    "ref_features = tsfel.extract_features_from_files(ref_sig_files, ref_fs, ref_dim)\n",
    "target_features = tsfel.extract_features_from_files(target_sig_files, target_fs, target_dim)\n",
    "\n",
    "print(\"Reference features shape:\", ref_features.shape)\n",
    "print(\"Synthetic features shape:\", target_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Space Visualization: UMAP Analysis of Real vs Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(n_neighbors=3, n_components=2, random_state=10, n_jobs=1)\n",
    "real_feats_2d = umap.fit_transform(ref_features)\n",
    "fake_feats_2d = umap.transform(target_features)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(real_feats_2d[:, 0], real_feats_2d[:, 1], s=20, label=\"Real Samples\")\n",
    "plt.scatter(fake_feats_2d[:, 0], fake_feats_2d[:, 1], s=20, label=\"Fake Samples\")\n",
    "plt.title(\"UMAP Features Visualization | Real vs Synthetic\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Improved Precision and Improved Recall (Dataset-level and Instance-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.time_series.measures.synthesis_val import ImprovedPrecision, ImprovedRecall\n",
    "\n",
    "ip = ImprovedPrecision(k=2)\n",
    "ir = ImprovedRecall(k=2)\n",
    "\n",
    "ip_result = ip.compute(ref_features, target_features)\n",
    "ir_result = ir.compute(ref_features, target_features)\n",
    "\n",
    "precision_dataset, precision_instance = ip_result.value\n",
    "recall_dataset, recall_instance = ir_result.value\n",
    "\n",
    "print(f\"Dataset-level Precision: {precision_dataset:.2f} | Dataset-level Recall: {recall_dataset:.2f}\")\n",
    "print(f\"Instance-level Precision: {precision_instance[:20]} | Instance-level Recall: {recall_instance[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Precise and Imprecise samples according to Improved Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_instances_grid(signals: list[np.ndarray], n_cols: int = 25):\n",
    "    n_rows = len(signals) // n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    for ax, signal in zip(axs.flat, signals):\n",
    "        ax.plot(signal[:, 0])  # ploting only Lead I\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_instance = np.array(precision_instance)\n",
    "imprecise_idx = np.argwhere(precision_instance < 1).flatten()\n",
    "precise_idx = np.argwhere(precision_instance >= 1).flatten()\n",
    "\n",
    "precise_samples = [target_data[i] for i in precise_idx]\n",
    "imprecise_samples = [target_data[i] for i in imprecise_idx]\n",
    "\n",
    "precise_fig = plot_instances_grid(precise_samples, n_cols=5)\n",
    "precise_fig.suptitle(\"Lead I of Precise Signals (All Leads Considered)\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "imprecise_fig = plot_instances_grid(imprecise_samples, n_cols=5)\n",
    "imprecise_fig.suptitle(\"Lead I of Imprecise Signals (All Leads Considered)\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Valitation using Distance Metrics\n",
    "\n",
    "In distance metrics such as Frechet Distance, Wasserstein Distance, and Maximum Mean Discrepancy (MMD), besides the metric value alone the `pymdma` package also computes two additional statistics: the dispersion ratio and the distance ratio.\n",
    "\n",
    "- **dispersion ratio**: computes the ratio of the distance between fake samples and the distance between real samples, providing insight into the variability of the generated data compared to the original data.\n",
    "- **distance ratio**: computes the ratio of the distance between real and fake samples and the distance of between real samples, indicating the dissimilarity between the two datasets in comparison to the internal variation within the real samples.\n",
    "\n",
    "An example of the Wasserstein distance value, along with the corresponding ratios, is provided above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.time_series.measures.synthesis_val import WassersteinDistance\n",
    "\n",
    "WD = WassersteinDistance()\n",
    "wd_result = WD.compute(ref_features, target_features)\n",
    "\n",
    "wd_dataset, _ = wd_result.value\n",
    "stats_dataset, _ = wd_result.stats\n",
    "\n",
    "\n",
    "dispersion_ratio = stats_dataset[\"dispersion_ratio\"]\n",
    "distance_ratio = stats_dataset[\"distance_ratio\"]\n",
    "print(\"Dataset-level information:\")\n",
    "print(f\"\\t{'Wasserstein Distance':<25}{wd_dataset:.2f}\")\n",
    "print(f\"\\t{'Distance Ratio':<25}{distance_ratio:.2f}\")\n",
    "print(f\"\\t{'Dispersion Ratio':<25}{dispersion_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values indicate that the distance between real and fake samples was 2.54 times greater than the distance between real samples, and that the variability among fake samples was 3.28 times higher than the variability between real samples. These ratios provide a more intuitive interpretation than the distance metric value alone, offering a clearer comparison of the variation between real and synthetic data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
