{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"pymdma[tabular]\" --find-links \"https://download.pytorch.org/whl/cpu/torch_stable.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbor Model\n",
    "\n",
    "\n",
    "def _get_nn_model(train: np.ndarray, distance_type: str = \"euclidean\"):\n",
    "    \"\"\"\n",
    "    Find nearest neighbors of test in train with first categoric_slice-many variables being categorical.\n",
    "\n",
    "    :param train: train pandas dataframe\n",
    "    :param cat_slice: where do category columns end\n",
    "\n",
    "    :returns: scikit learn nearest_neighbor_model fit with train data\n",
    "\n",
    "    \"\"\"\n",
    "    nearest_neighbor_model = NearestNeighbors(\n",
    "        metric=distance_type,\n",
    "        algorithm=\"ball_tree\",\n",
    "        n_jobs=None,\n",
    "    )\n",
    "    nearest_neighbor_model.fit(train)\n",
    "\n",
    "    return nearest_neighbor_model\n",
    "\n",
    "\n",
    "# Distances\n",
    "def _get_nn_distances(\n",
    "    tgt_emb: np.ndarray, syn_emb: np.ndarray, distance_type: dict = \"euclidean\", size: int = None\n",
    ") -> Tuple[np.ndarray]:\n",
    "    # checkpoint\n",
    "    assert tgt_emb.shape[1] == syn_emb.shape[1], \"Train and Syn have mismatched columns\"\n",
    "\n",
    "    # split into tgt_train, tgt_query, and syn_query\n",
    "    if size is None:\n",
    "        tgt_size, syn_size = len(tgt_emb), len(syn_emb)\n",
    "    else:\n",
    "        tgt_size, syn_size = size, size\n",
    "\n",
    "    # train and query from target\n",
    "    tgt_query = tgt_emb[-int(tgt_size) :]\n",
    "\n",
    "    # syn_train is not needed\n",
    "    # if sample_size = synthetic_size, syn_query is all syn dataset\n",
    "    syn_query = syn_emb[-int(syn_size) :]\n",
    "\n",
    "    # training model\n",
    "    nn_model = _get_nn_model(tgt_query, distance_type)\n",
    "\n",
    "    # get nearest neighbors\n",
    "    # target\n",
    "    tgt_query_nn, _ = nn_model.kneighbors(tgt_query, n_neighbors=3)\n",
    "    tgt_query_nn = tgt_query_nn[:, 1:]  # except the closest (itself)\n",
    "\n",
    "    # synthetic\n",
    "    syn_query_nn, _ = nn_model.kneighbors(syn_query, n_neighbors=2)\n",
    "\n",
    "    # calculating DCR NNDR\n",
    "    query_dict = {\"tgt\": tgt_query_nn, \"syn\": syn_query_nn}\n",
    "\n",
    "    # compute privacy distances\n",
    "    dcr, nndr = {}, {}\n",
    "    for label, query in query_dict.items():\n",
    "        # closest neighbor\n",
    "        aux_dcr = query[:, 0]\n",
    "\n",
    "        # normalized closest neighbor distances\n",
    "        aux_nndr = aux_dcr / (query[:, 1] + 1e-10)\n",
    "\n",
    "        # assign\n",
    "        dcr[label] = aux_dcr\n",
    "        nndr[label] = aux_nndr\n",
    "\n",
    "    return dcr, nndr\n",
    "\n",
    "\n",
    "# Probability Density Function\n",
    "def _get_nn_pdf(\n",
    "    tgt_dist: np.ndarray,\n",
    "    syn_dist: np.ndarray,\n",
    ") -> Tuple[np.ndarray]:\n",
    "\n",
    "    # get distributions bins\n",
    "    t_min, t_max = min(tgt_dist), max(tgt_dist)\n",
    "    s_min, s_max = min(syn_dist), max(syn_dist)\n",
    "    bins = np.linspace(min([t_min, s_min]), max([t_max, s_max]), 600)\n",
    "\n",
    "    # get distributions\n",
    "    # tgt pdf dists\n",
    "    pdf_tgt = gaussian_kde(tgt_dist).pdf(bins)\n",
    "    pdf_tgt /= sum(pdf_tgt)\n",
    "\n",
    "    # syn pdf dists\n",
    "    pdf_syn = gaussian_kde(syn_dist).pdf(bins)\n",
    "    pdf_syn /= sum(pdf_syn)\n",
    "\n",
    "    return pdf_tgt, pdf_syn, bins\n",
    "\n",
    "\n",
    "def subplot_dim_optm(dim: int):\n",
    "    import math\n",
    "\n",
    "    matrix_n, matrix_m = int(np.sqrt(dim)), int(np.sqrt(dim))\n",
    "    matrix_n += math.ceil((dim - matrix_m**2) / matrix_n)\n",
    "    return matrix_n, matrix_m\n",
    "\n",
    "\n",
    "# Plot Generative Quality\n",
    "\n",
    "\n",
    "def plot_generative_quality(\n",
    "    real_data_list: List[np.ndarray],\n",
    "    fake_data_list: List[np.ndarray],\n",
    "    real_pdf_list: List[np.ndarray],\n",
    "    fake_pdf_list: List[np.ndarray],\n",
    "    bins_list: List[np.ndarray],\n",
    "    names: List[str],\n",
    "    emb_obj: Callable,\n",
    "):\n",
    "    # plot matrix dim\n",
    "    n_dim, m_dim = subplot_dim_optm(dim=len(real_data_list))\n",
    "\n",
    "    # figures\n",
    "    fig1, axes_emb = plt.figure(n_dim, m_dim, figsize=(12, 8))\n",
    "    fig2, axes_dist = plt.figure(n_dim, m_dim, figsize=(12, 8))\n",
    "\n",
    "    # flatten axes array\n",
    "    axes_emb = axes_emb.flatten()\n",
    "    axes_dist = axes_dist.flatten()\n",
    "\n",
    "    # loop\n",
    "    for real_data, fake_data, real_pdf, fake_pdf, bins, name, ax_emb, ax_dist in zip(\n",
    "        real_data_list, fake_data_list, real_pdf_list, fake_pdf_list, bins_list, names, axes_emb, axes_dist\n",
    "    ):\n",
    "        # embeddings\n",
    "        tgt_emb2d = emb_obj.transform(real_data)\n",
    "        syn_emb2d = emb_obj.transform(fake_data)\n",
    "\n",
    "        ax_emb.scatter(tgt_emb2d[:, 0], tgt_emb2d[:, 1], color=\"forestgreen\", marker=\"o\", label=\"Real\", alpha=0.7)\n",
    "        ax_emb.scatter(syn_emb2d[:, 0], syn_emb2d[:, 1], color=\"darkred\", marker=\"*\", label=\"Fake\", alpha=0.7)\n",
    "\n",
    "        # set settings\n",
    "        ax_emb.legend()\n",
    "        ax_emb.set_xlabel(\"Embedding nr. 0\")\n",
    "        ax_emb.set_ylabel(\"Embedding nr. 1\")\n",
    "\n",
    "        # set title\n",
    "        ax_emb.set_title(name)\n",
    "\n",
    "        # distances plot\n",
    "        ax_dist.plot(bins, real_pdf, color=\"forestgreen\", label=\"Real\")\n",
    "        ax_dist.fill_between(bins, real_pdf, 0, color=\"forestgreen\", alpha=0.1)\n",
    "\n",
    "        ax_dist.plot(bins, fake_pdf, color=\"darkred\", label=\"Fake\")\n",
    "        ax_dist.fill_between(bins, fake_pdf, 0, color=\"darkred\", alpha=0.1)\n",
    "\n",
    "        # set settings\n",
    "        ax_dist.legend()\n",
    "        ax_dist.set_xlabel(\"Distances\")\n",
    "        ax_dist.set_ylabel(\"Relative Frequency\")\n",
    "\n",
    "        # set title\n",
    "        ax_dist.set_title(name)\n",
    "\n",
    "    # figures\n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "\n",
    "    return fig1, fig2\n",
    "\n",
    "\n",
    "def make_dataset(*args, **kwargs):\n",
    "    # generated data\n",
    "    X, y = make_classification(*args, **kwargs)\n",
    "\n",
    "    # columns\n",
    "    cols = [f\"att_{idx}\" for idx in range(X.shape[-1])]\n",
    "\n",
    "    # dataframe conversion\n",
    "    X_df = pd.DataFrame(X, columns=cols)\n",
    "    X_df[\"tgt\"] = y\n",
    "\n",
    "    return X_df\n",
    "\n",
    "\n",
    "# Plot datasets\n",
    "def plot_datasets(\n",
    "    dataset_list: List[np.ndarray],\n",
    "    names: List[str],\n",
    "    emb_obj: Callable,\n",
    "    with_fit: bool = True,\n",
    "    share_ax: bool = True,\n",
    "):\n",
    "    # plot matrix dim\n",
    "    dim = len(dataset_list)\n",
    "    n_dim, m_dim = subplot_dim_optm(dim=dim)\n",
    "\n",
    "    # figures\n",
    "    if share_ax:\n",
    "        fig, axes = plt.subplots(n_dim, m_dim, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(n_dim, m_dim, figsize=(12, 8))\n",
    "\n",
    "    # flatten axes array\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # choose a color map\n",
    "    colors = plt.cm.get_cmap(\"tab10\", dim).colors\n",
    "\n",
    "    # loop\n",
    "    for dataset, name, color, ax in zip(dataset_list, names, colors, axes):\n",
    "        # embeddings\n",
    "        data_emb = emb_obj.fit_transform(dataset) if with_fit else emb_obj.transform(dataset)\n",
    "\n",
    "        # scatter plot\n",
    "        ax.scatter(data_emb[:, 0], data_emb[:, 1], facecolors=color, edgecolors=color, marker=\"o\", alpha=0.7)\n",
    "\n",
    "        # set settings\n",
    "        ax.set_xlabel(\"Embedding nr. 0\")\n",
    "        ax.set_ylabel(\"Embedding nr. 1\")\n",
    "\n",
    "        # set title\n",
    "        ax.set_title(name)\n",
    "\n",
    "    # figures\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # display\n",
    "    fig.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def _get_1d_pdf(data: np.ndarray, n_bins: int = 300):\n",
    "    # get distributions bins\n",
    "    d_min, d_max = min(data), max(data)\n",
    "    bins = np.linspace(d_min, d_max, n_bins)\n",
    "\n",
    "    # get distributions\n",
    "    # tgt pdf dists\n",
    "    pdf = gaussian_kde(data.astype(float)).pdf(bins)\n",
    "    pdf /= sum(pdf)\n",
    "\n",
    "    return pdf, bins\n",
    "\n",
    "\n",
    "def plot_kde(\n",
    "    reference: np.ndarray,\n",
    "    target_list: List[np.ndarray],\n",
    "    column_names: List[str] = None,\n",
    "    tag_names: List[str] = None,\n",
    "    annots: np.ndarray = None,\n",
    "):\n",
    "    num_columns = reference.shape[1]\n",
    "    num_datasets = len(target_list)\n",
    "\n",
    "    # default feature names if not provided\n",
    "    if column_names is None:\n",
    "        column_names = [f\"Col {i+1}\" for i in range(reference.shape[-1])]\n",
    "\n",
    "    if tag_names is None:\n",
    "        tag_names = [f\"Dataset {i+1}\" for i in range(len(target_list))]\n",
    "\n",
    "    # set up the plot grid\n",
    "    fig, axes = plt.subplots(num_columns, num_datasets, figsize=(16, 10))\n",
    "\n",
    "    for i in range(num_columns):\n",
    "        # iterate through each feature (row in subplot grid)\n",
    "        ref_pdf, ref_bins = _get_1d_pdf(reference[:, i], n_bins=400)\n",
    "\n",
    "        # set ylabel\n",
    "        axes[i, 0].set_ylabel(column_names[i])\n",
    "\n",
    "        # iterate\n",
    "        for j, target in enumerate(target_list):\n",
    "            # plot KDEs for each target dataset (columns in subplot grid)\n",
    "            at = AnchoredText(str(annots[i, j]), prop=dict(size=7), frameon=False, loc=\"upper right\")\n",
    "\n",
    "            # target\n",
    "            tgt_pdf, tgt_bins = _get_1d_pdf(target[:, i], n_bins=400)\n",
    "\n",
    "            # plot the reference KDE on each row\n",
    "            axes[i, j].plot(ref_bins, ref_pdf, color=\"forestgreen\", label=\"Real\", ls=\"--\", alpha=0.3)\n",
    "            axes[i, j].fill_between(ref_bins, ref_pdf, 0, color=\"forestgreen\", alpha=0.1)\n",
    "\n",
    "            # plot the target KDE on each row\n",
    "            axes[i, j].plot(tgt_bins, tgt_pdf, color=\"indianred\", label=\"Target\", ls=\"--\", alpha=0.3)\n",
    "            axes[i, j].fill_between(tgt_bins, tgt_pdf, 0, color=\"indianred\", alpha=0.1)\n",
    "\n",
    "            # add annotation\n",
    "            axes[i, j].add_artist(at)\n",
    "\n",
    "            # window params\n",
    "            if not i:\n",
    "                axes[i, j].set_title(f\"{tag_names[j]}\")\n",
    "\n",
    "            axes[i, j].set_yticks([])\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].grid()\n",
    "\n",
    "    # display\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input validation\n",
    "# A --> High Volume of Samples + Informative Features\n",
    "tag_in1 = \"A\"\n",
    "name_in1 = \"A - High Vol. + Inform.\"\n",
    "dataset_in1 = make_dataset(\n",
    "    n_samples=2000,\n",
    "    n_features=10,\n",
    "    n_informative=10,\n",
    "    n_repeated=0,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=None,\n",
    "    flip_y=0.01,\n",
    "    shift=0.0,\n",
    "    scale=3.0,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ").to_numpy()\n",
    "\n",
    "# B --> High Volume of Samples + Non-Informative Features\n",
    "tag_in2 = \"B\"\n",
    "name_in2 = \"B - High Vol. + Non-Inform.\"\n",
    "dataset_in2 = make_dataset(\n",
    "    n_samples=2000,\n",
    "    n_features=10,\n",
    "    n_informative=1,\n",
    "    n_repeated=3,\n",
    "    n_redundant=6,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=None,\n",
    "    flip_y=0.01,\n",
    "    shift=0.0,\n",
    "    scale=3.0,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ").to_numpy()\n",
    "\n",
    "# C --> Small Volume of Samples + High Dimensionality + Informative Features\n",
    "tag_in3 = \"C\"\n",
    "name_in3 = \"C - Small Vol. + Inform.\"\n",
    "dataset_in3 = make_dataset(\n",
    "    n_samples=200,\n",
    "    n_features=100,\n",
    "    n_informative=95,\n",
    "    n_repeated=2,\n",
    "    n_redundant=3,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=None,\n",
    "    flip_y=0.01,\n",
    "    shift=0.0,\n",
    "    scale=3.0,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ").to_numpy()\n",
    "\n",
    "# D --> Small Volume of Samples + High Dimensionality + Non-informative Features\n",
    "tag_in4 = \"D\"\n",
    "name_in4 = \"D - Small Vol. + Non-Inform.\"\n",
    "dataset_in4 = make_dataset(\n",
    "    n_samples=200,\n",
    "    n_features=100,\n",
    "    n_informative=1,\n",
    "    n_repeated=0,\n",
    "    n_redundant=99,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=None,\n",
    "    flip_y=0.01,\n",
    "    shift=0.0,\n",
    "    scale=3.0,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ").to_numpy()\n",
    "\n",
    "## Synthesis Evaluation\n",
    "# reference dataset\n",
    "tag_ref = \"R\"\n",
    "name_ref = \"R - Reference Dataset\"\n",
    "dataset_ref = make_dataset(\n",
    "    n_samples=2000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    n_repeated=2,\n",
    "    n_redundant=3,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=None,\n",
    "    flip_y=0.01,\n",
    "    shift=0.0,\n",
    "    scale=3.0,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ").to_numpy()\n",
    "\n",
    "# A --> random dataset\n",
    "tag_syn1 = \"A\"\n",
    "name_syn1 = \"A - Random\"\n",
    "dataset_s1 = np.random.random(dataset_ref.shape) * 3.0\n",
    "\n",
    "# B --> cumulative small distortion\n",
    "tag_syn2 = \"B\"\n",
    "name_syn2 = \"B - Small Add Distortion\"\n",
    "rnd = np.random.random(dataset_ref.shape) * 0.01\n",
    "dataset_s2 = np.copy(dataset_ref) + rnd\n",
    "\n",
    "# C --> cumulative large distortion\n",
    "tag_syn3 = \"C\"\n",
    "name_syn3 = \"C - Large Add Distortion\"\n",
    "rnd = np.random.random(dataset_ref.shape) * 100\n",
    "dataset_s3 = np.copy(dataset_ref) + rnd\n",
    "\n",
    "# D --> small multiplicative distortion\n",
    "tag_syn4 = \"D\"\n",
    "name_syn4 = \"D - Small Mult. Distortion\"\n",
    "rnd = 0.7\n",
    "dataset_s4 = np.copy(dataset_ref) * rnd\n",
    "\n",
    "# E --> large multiplicative distortion\n",
    "tag_syn5 = \"E\"\n",
    "name_syn5 = \"E - Large Mult. Distortion\"\n",
    "rnd = 100\n",
    "dataset_s5 = np.copy(dataset_ref) * rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.embeddings.scale import StandardNorm\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# Z-score scaler\n",
    "scale_obj = StandardNorm()\n",
    "\n",
    "# input validation\n",
    "dataset_list = [dataset_in1, dataset_in2, dataset_in3, dataset_in4]\n",
    "dataset_norm = list(map(lambda x: scale_obj.fit_transform(x), dataset_list))\n",
    "names = [name_in1, name_in2, name_in3, name_in4]\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_norm, names, emb_obj, with_fit=True, share_ax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.embeddings.scale import StandardNorm\n",
    "\n",
    "# reference dataset\n",
    "ref = np.copy(dataset_ref)\n",
    "\n",
    "# normalizer\n",
    "# Z-score scaler\n",
    "scale_obj = StandardNorm()\n",
    "\n",
    "# fit with reference data\n",
    "ref = scale_obj.fit_transform(ref)\n",
    "\n",
    "# embedder\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# fit with reference data\n",
    "emb_obj.fit(ref)\n",
    "\n",
    "# input validation\n",
    "dataset_list = [dataset_ref, dataset_s1, dataset_s2, dataset_s3, dataset_s4, dataset_s5]\n",
    "dataset_norm = list(map(lambda x: scale_obj.transform(x), dataset_list))\n",
    "names = [name_ref, name_syn1, name_syn2, name_syn3, name_syn4, name_syn5]\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_norm, names, emb_obj, with_fit=False, share_ax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Validation\n",
    "\n",
    "In the tabular modality, the pymdma package provides one type of input validation:\n",
    "- **no-reference**: The tabular dataset is validated without any reference set of data.\n",
    "\n",
    "This section will demonstrate how to use some of the input validation metrics provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Reference Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# input validation\n",
    "dataset_list = [dataset_in1, dataset_in2, dataset_in3, dataset_in4]\n",
    "names = [name_in1, name_in2, name_in3, name_in4]\n",
    "tag_list = [tag_in1, tag_in2, tag_in3, tag_in4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.measures.input_val import KAnonymityScore\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# privacy\n",
    "score_name = \"KAnonimity\"\n",
    "k_anom = KAnonymityScore(column_names=None, qi_names=None)  # K-anonimity\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_list, tag_list):\n",
    "    # compute\n",
    "    aux_score = round(k_anom.compute(dataset).value[0], 2)\n",
    "\n",
    "    # append\n",
    "    scores.append(f\"{tag} - {score_name} = {aux_score}\")\n",
    "\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_list, scores, emb_obj, with_fit=True, share_ax=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.measures.input_val import VIFactorScore\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# quality\n",
    "score_name = \"VIF Score\"\n",
    "vif = VIFactorScore(column_names=None)  # VIF\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_list, tag_list):\n",
    "    # compute\n",
    "    aux_score = round(vif.compute(dataset).value[0], 2)\n",
    "\n",
    "    # append\n",
    "    scores.append(f\"{tag} - {score_name} = {aux_score}\")\n",
    "\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_list, scores, emb_obj, with_fit=True, share_ax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.measures.input_val import DimCurseScore\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# quality\n",
    "score_name = \"Dim. Curse\"\n",
    "dimc = DimCurseScore()  # Dimensionality Curse\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_list, tag_list):\n",
    "    # compute\n",
    "    aux_score = round(dimc.compute(dataset).value[0], 2)\n",
    "\n",
    "    # append\n",
    "    scores.append(f\"{tag} - {score_name} = {aux_score}\")\n",
    "\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_list, scores, emb_obj, with_fit=True, share_ax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.measures.input_val import UniformityScore\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# quality\n",
    "score_name = \"Uniformity\"\n",
    "unif = UniformityScore(column_names=None)  # Uniformity\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_list, tag_list):\n",
    "    # compute\n",
    "    aux_score = list(unif.compute(dataset).stats[0].values())\n",
    "\n",
    "    # append\n",
    "    scores.append(f\"{tag} - {score_name} = \" + f\"{round(aux_score[0], 1)}\" + \"\\u00b1\" + f\"{round(aux_score[1], 1)} %\")\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_list, scores, emb_obj, with_fit=True, share_ax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.measures.input_val import OutlierScore\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# quality\n",
    "score_name = \"Outlier Score\"\n",
    "outl = OutlierScore()  # Outliers\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_list, tag_list):\n",
    "    # compute\n",
    "    aux_score = list(outl.compute(dataset).stats[0].values())\n",
    "\n",
    "    # append\n",
    "    scores.append(f\"{tag} - {score_name} = \" + f\"{round(aux_score[0], 1)}\" + \"\\u00b1\" + f\"{round(aux_score[1], 1)} %\")\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_list, scores, emb_obj, with_fit=True, share_ax=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Validation\n",
    "\n",
    "The automatic evaluation of synthetically generated tabular data is a common practice in the field of generative AI, and is crucial for the assessment of the quality of large synthetic datasets. This is usually done by comparing the synthetic records to a set of reference records by considering the similarity between the distributions of the two sets. \n",
    "\n",
    "In this section, we will demonstrate how to use the `pymdma` package to evaluate the quality of synthetic tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# input validation\n",
    "dataset_list = [dataset_ref, dataset_s1, dataset_s2, dataset_s3, dataset_s4, dataset_s5]  # target dataset list\n",
    "ref = np.copy(dataset_ref)  # reference dataset\n",
    "names = [name_ref, name_syn1, name_syn2, name_syn3, name_syn4, name_syn5]  # dataset names\n",
    "tag_list = [tag_ref, tag_syn1, tag_syn2, tag_syn3, tag_syn4, tag_syn5]  # dataset tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.embeddings.embed import UMAPEmbedder\n",
    "from pymdma.tabular.embeddings.scale import StandardNorm\n",
    "\n",
    "# Z-score scaling\n",
    "scale_obj = StandardNorm()\n",
    "\n",
    "# fit with reference data\n",
    "ref = scale_obj.fit_transform(ref)\n",
    "\n",
    "# umap embedder\n",
    "emb_obj = UMAPEmbedder(n_components=2)\n",
    "\n",
    "# fit with reference data\n",
    "emb_obj.fit(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the list of datasets for evaluation\n",
    "dataset_norm_list = [scale_obj.transform(dset) for dset in dataset_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision + Recall + Authenticity + Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.measures.synthesis_val import Authenticity, Coverage, ImprovedPrecision, ImprovedRecall\n",
    "\n",
    "ip, ip_name = ImprovedPrecision(k=5), \"P\"\n",
    "ir, ir_name = ImprovedRecall(k=5), \"R\"\n",
    "aut, aut_name = Authenticity(k=5), \"A\"\n",
    "cov, cov_name = Coverage(k=5), \"C\"\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_norm_list, tag_list):\n",
    "    # compute\n",
    "    precision = ip.compute(ref, dataset).value[0]\n",
    "    recall = ir.compute(ref, dataset).value[0]\n",
    "    autenticity = aut.compute(ref, dataset).value[0]\n",
    "    coverage = cov.compute(ref, dataset).value[0]\n",
    "\n",
    "    # aggregate all scores\n",
    "    aux_scores = [precision, recall, autenticity, coverage]\n",
    "    aux_names = [ip_name, ir_name, aut_name, cov_name]\n",
    "\n",
    "    # get score in string format\n",
    "    score_s = \" | \".join([f\"{name}={score}\" for name, score in zip(aux_names, aux_scores)])\n",
    "\n",
    "    # assign\n",
    "    if tag != tag_ref:\n",
    "        # append\n",
    "        scores.append(f\"Dataset {tag} - {score_s}\")\n",
    "    else:\n",
    "        # append\n",
    "        scores.append(f\"Reference Dataset - {score_s}\")\n",
    "\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_norm_list, scores, emb_obj, with_fit=False, share_ax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Similarity + Correlation Coherence + Distance to Closest Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.measures.synthesis_val import CoherenceScore, DCRPrivacy, StatisticalSimScore\n",
    "\n",
    "ssim, ssim_name = StatisticalSimScore(), \"AttSim\"\n",
    "coher, coher_name = CoherenceScore(weights=None, corr_type=\"pearson\"), \"CorrCoH\"\n",
    "dcr, dcr_name = DCRPrivacy(distance_type=\"euclidean\"), \"DCR\"\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_norm_list, tag_list):\n",
    "    # compute\n",
    "    ssim_score = ssim.compute(ref, dataset).stats[0].get(\"mean\")\n",
    "    coher_score = coher.compute(ref, dataset).value[0]\n",
    "    dcr_score = dcr.compute(ref, dataset).value[0].get(\"privacy\")\n",
    "\n",
    "    # aggregate all scores\n",
    "    aux_scores = [ssim_score, coher_score, dcr_score]\n",
    "    aux_names = [ssim_name, coher_name, dcr_name]\n",
    "\n",
    "    # get score in string format\n",
    "    score_s = \" | \".join([f\"{name}={score}\" for name, score in zip(aux_names, aux_scores)])\n",
    "\n",
    "    # assign\n",
    "    if tag != tag_ref:\n",
    "        # append\n",
    "        scores.append(f\"Dataset {tag} - {score_s}\")\n",
    "    else:\n",
    "        # append\n",
    "        scores.append(f\"Reference Dataset - {score_s}\")\n",
    "\n",
    "\n",
    "# plot\n",
    "_ = plot_datasets(dataset_norm_list, scores, emb_obj, with_fit=False, share_ax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Divergence Score (1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdma.tabular.measures.synthesis_val import StatisiticalDivergenceScore\n",
    "\n",
    "# statistical similarity\n",
    "sdiv, sdiv_name = StatisiticalDivergenceScore(), \"StatDiv\"\n",
    "\n",
    "# score list\n",
    "scores = []\n",
    "\n",
    "# compute scores\n",
    "for dataset, tag in zip(dataset_norm_list, tag_list):\n",
    "    # compute\n",
    "    ssim_score = sdiv.compute(ref, dataset).value[0]\n",
    "    ssim_score = list(ssim_score.values())\n",
    "\n",
    "    # append\n",
    "    scores.append(ssim_score)\n",
    "\n",
    "# transpose\n",
    "scores_np = np.array(scores).T.round(2).squeeze(0)\n",
    "\n",
    "# plot\n",
    "fig = plot_kde(reference=ref, target_list=dataset_norm_list, tag_names=names, annots=scores_np)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
